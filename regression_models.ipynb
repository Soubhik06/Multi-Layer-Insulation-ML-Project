{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "data = pd.read_csv('heat_transfer_multilayer_dataset.csv')\n",
        "target = \"Q\"\n",
        "features = None\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "save_pred_csv = True\n",
        "\n",
        "df = pd.read_csv('heat_transfer_multilayer_dataset.csv')\n",
        "print(\"Data Shape: \", df.shape)\n",
        "print(\"Columns: \", df.columns.tolist())\n",
        "\n",
        "if target not in df.columns:\n",
        "  raise ValueError(f\"Target columns '{target}' is not found in the dataset.\")\n",
        "\n",
        "\n",
        "if features is None:\n",
        "  numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "  feature_columns = [c for c in numeric_columns if c != target]\n",
        "  print(\"Auto Selected numeric feature columns:\", feature_columns)\n",
        "\n",
        "else:\n",
        "  feature_columns = features\n",
        "  missing = [c for c in feature_columns if c != target]\n",
        "  if missing:\n",
        "    raise ValueError(f\"Missing feature columns: {missing}\")\n",
        "\n",
        "X = df[feature_columns].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "models ={\n",
        "    \"Linear Regression\": LinearRegression(), # Changed from LogisticRegression\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE, verbosity=0),\n",
        "    \"Neural Network (MLP)\": MLPRegressor(random_state=RANDOM_STATE, max_iter=500)}\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    results.append({\"model\": name, \"MSE\": mse, \"MAE\": mae, \"R²\": r2, \"RMSE\": rmse})\n",
        "    print(f\"{name} -> MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
        "\n",
        "\n",
        "results_df=pd.DataFrame(results).set_index(\"model\")\n",
        "print(\"\\n---Summary---\")\n",
        "print(results_df.sort_values(\"RMSE\"))\n",
        "\n",
        "results_df.to_csv(\"models_performance_summary.csv\")\n",
        "print(\"\\nSaved Performance Summary to models_performance_summary.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739cf3c6-4da9-4d07-ccac-eadf6ee65625",
        "id": "VXqDKN6l-rfs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape:  (1000, 17)\n",
            "Columns:  ['delta_T', 'Mat1', 'L1', 'k1', 'Mat2', 'L2', 'k2', 'Mat3', 'L3', 'k3', 'Mat4', 'L4', 'k4', 'Mat5', 'L5', 'k5', 'Q']\n",
            "Auto Selected numeric feature columns: ['delta_T', 'L1', 'k1', 'L2', 'k2', 'L3', 'k3', 'L4', 'k4', 'L5', 'k5']\n",
            "Linear Regression -> MSE: 1227420.8949, MAE: 562.1715, R²: 0.1963, RMSE: 1107.8903\n",
            "Decision Tree -> MSE: 465909.5189, MAE: 163.1172, R²: 0.6949, RMSE: 682.5757\n",
            "Random Forest -> MSE: 259879.1074, MAE: 142.2110, R²: 0.8298, RMSE: 509.7834\n",
            "XGBoost -> MSE: 232190.4839, MAE: 124.1431, R²: 0.8480, RMSE: 481.8615\n",
            "Neural Network (MLP) -> MSE: 1167751.7062, MAE: 480.0311, R²: 0.2354, RMSE: 1080.6256\n",
            "\n",
            "---Summary---\n",
            "                               MSE         MAE        R²         RMSE\n",
            "model                                                                \n",
            "XGBoost               2.321905e+05  124.143094  0.847969   481.861478\n",
            "Random Forest         2.598791e+05  142.211007  0.829839   509.783393\n",
            "Decision Tree         4.659095e+05  163.117250  0.694937   682.575651\n",
            "Neural Network (MLP)  1.167752e+06  480.031060  0.235393  1080.625609\n",
            "Linear Regression     1.227421e+06  562.171458  0.196324  1107.890290\n",
            "\n",
            "Saved Performance Summary to models_performance_summary.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}